import { ChatPromptTemplate, MessagesPlaceholder } from "@langchain/core/prompts";
import { RunnableSequence } from "@langchain/core/runnables";
import productModel from "../../../../models/Product.js";
import aiChatbotModel from "../../../../models/Chatbot.js";
import pool from "../../../../models/db.js";
import { extractSQL } from "../extra/parser.js";
import { loadSchema } from "../extra/schemaLoader.js";
import slugify from "slugify";
import { saveChatHistory } from "../memory/saveChatHistory.js";
import { searchSimilar } from "../vectorStore.js";
import { encrypt } from "../extra/encrypt.js";
import { ChatOpenAI } from "@langchain/openai";
import { getVectorStore } from "../vectorStore.js";

const model = new ChatOpenAI({
    openAIApiKey: process.env.OPENAI_API_KEY,
    modelName: "gpt-4o",
    temperature: 0.3,
});

export const sql_generator = async ({ messages, email, history, intent }) => {
    const products = await productModel.getAll();

    const productList = products
        .map(p => `${p.name} (gi√° ${p.price}ƒë)`)
        .join(", ");

    const schema = await loadSchema();
    // const formattedHistory = (history || [])
    //     .map(m => `${m.role === "user" ? "KH" : "AI"}: ${m.content}`)
    //     .join("\n");

    const sqlPromptTemplate = ChatPromptTemplate.fromMessages([
        ["system", `
B·∫°n l√† AI sinh c√¢u l·ªánh SQL t·ª´ c√¢u h·ªèi kh√°ch h√†ng v√† c√°c ch√≠nh s√°ch c·ªßa shop.

Y√™u c·∫ßu:
- Ch·ªâ sinh c√¢u l·ªánh SELECT ƒë√∫ng c√∫ ph√°p theo schema b√™n d∆∞·ªõi.
- KH√îNG ƒë∆∞·ª£c sinh UPDATE, DELETE, INSERT, DROP.
- N·∫øu truy v·∫•n t·ª´ b·∫£ng product th√¨ PH·∫¢I LU√îN bao g·ªìm c·ªôt \`id\`, \`discount_percentage\` v√† \`name\` trong SELECT (ƒë·ªÉ t·∫°o li√™n k·∫øt s·∫£n ph·∫©m).
- V√≠ d·ª•: h·ªèi gi√° th√¨ c·∫ßn SELECT id, name, price, discount_percentage.
- KH√îNG gi·∫£i th√≠ch. Tr·∫£ v·ªÅ SQL duy nh·∫•t b√™n trong block: \`\`\`sql ... \`\`\`

Schema:
{schema}

danh s√°ch s·∫£n ph·∫©m (**D·ª±a v√†o ƒë√¢y ƒë·ªÉ s·ª≠a ch√≠nh t·∫£ kh√°ch h√†ng**):
${productList}

L·ªãch s·ª≠ t∆∞∆°ng t√°c kh√°ch h√†ng (trong db):
{historyFormatted} 

H√£y s·ª≠ d·ª•ng th√¥ng tin l·ªãch s·ª≠ n√†y ƒë·ªÉ h·ªçc v·ªÅ kh√°ch h√†ng, r√∫t kinh nghi·ªám sai l·∫ßm c·ªßa m√¨nh v√† tr·∫£ l·ªùi c√¢u h·ªèi m·ªõi m·ªôt c√°ch ch√≠nh x√°c v√† h·ªèi l·∫°i kh√°ch h√†ng.

`],
        ["human", `Email: {email}`],
        new MessagesPlaceholder("messages")
    ]);

    const userQuestion = messages.at(-1)?.content || "";

    console.log("‚úÖ intent in sql gen:", intent);

    const encryptedMessage = encrypt(intent);
    const rawHistory = await aiChatbotModel.findByMessageAndEmail(encryptedMessage, email);

    const historyFormatted = rawHistory.map(row => {
        return `KH: ${row.question}\nAI: ${row.ai_answer}`;
    }).join("\n");

    // const similar = await searchSimilar(userQuestion, 5, intent, 0.05);
    // const context = similar.map(doc =>
    //     `KH: ${doc.pageContent}\nAI: ${doc.metadata.answer}`
    // ).join("\n");

    const sqlChain = RunnableSequence.from([sqlPromptTemplate, model]);

    // const response = await sqlChain.invoke({ messages, schema, email, context, historyFormatted });

    const response = await sqlChain.invoke({ messages, schema, email, historyFormatted });

    const sql = extractSQL(response.content);
    console.log("‚úÖ SQL:", sql);
    return { sql, current_step: "sql_executor" };
};

export const sql_executor = async ({ sql }) => {
    const lowerSQL = sql?.toLowerCase() || "";
    if (!lowerSQL.startsWith("select") || /update|delete|insert|drop/.test(lowerSQL)) {
        return {
            messages: [{ content: "‚ö†Ô∏è Bill ch·ªâ h·ªó tr·ª£ truy v·∫•n SELECT." }],
            current_step: "__end__"
        };
    }
    let dbRows = [];
    try {
        if (sql) [dbRows] = await pool.execute(sql);
    } catch (err) {
        return {
            messages: [{ content: `‚ùå L·ªói SQL: ${err.message}` }],
            current_step: "__end__"
        };
    }
    return { dbRows, current_step: "result_refiner" };
};

export const result_refiner = async ({ messages, dbRows, history, intent, email }) => {
    await getVectorStore("sql_docs");
    const schema = await loadSchema();
    const formattedHistory = (history || [])
        .map(m => `${m.role === "user" ? "KH" : "AI"}: ${m.content}`)
        .join("\n");
    if (!dbRows || dbRows.length === 0) {
        return {
            refined: "‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p.",
            resultMessage: "",
            messages: [{ content: "‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p." }],
            current_step: "__end__"
        };
    }

    const headers = Object.keys(dbRows[0]).join(" | ");
    const rows = dbRows.map(r => Object.values(r).join(" | ")).join("\n");
    let raw = `‚úÖ K·∫øt qu·∫£:\n${headers}\n${rows}`;

    const urls = dbRows.filter(r => r.id && r.name).map(r => {
        const slug = slugify(r.name, { lower: true });
        return `[${r.name}](${process.env.FRONTEND_URL_NEXT}/san-pham/${slug}-${r.id})`;
    });

    if (urls.length > 0) raw += `\nüì¶ Xem chi ti·∫øt:\n${urls.join("\n")}`;

    const refinePrompt = ChatPromptTemplate.fromMessages([
        ["system", `
B·∫°n l√† tr·ª£ l√Ω AI c·∫ßu l√¥ng. D∆∞·ªõi ƒë√¢y l√† c√¢u h·ªèi c·ªßa kh√°ch h√†ng: {userQuestion} v√† d·ªØ li·ªáu th√¥ t·ª´ k·∫øt qu·∫£ SQL. H√£y di·ªÖn gi·∫£i l·∫°i th√¥ng tin m·ªôt c√°ch l·ªãch s·ª±, d·ªÖ hi·ªÉu v√† NG·∫ÆN G·ªåN cho kh√°ch h√†ng.

LU·∫¨T:
- N·∫øu d·ªØ li·ªáu l√† r·ªóng th√¨ tr·∫£ l·ªùi kh√¥ng c√≥ k·∫øt qu·∫£.
- N·∫øu trong d·ªØ li·ªáu c√≥ li√™n k·∫øt Markdown (d·∫°ng [T√™n](url)) th√¨ PH·∫¢I GI·ªÆ NGUY√äN.
- KH√îNG ƒë∆∞·ª£c t·ª± √Ω b·ªè li√™n k·∫øt, thay ƒë·ªïi URL, ho·∫∑c c·∫Øt b·ªè ph·∫ßn \"üì¶ Xem chi ti·∫øt\".

Schema:
{schema}

L·ªãch s·ª≠ giao ti·∫øp (·ªü database):
{historyFormatted}

L·ªãch s·ª≠ c√≥ embedding vector g·∫ßn gi·ªëng nh·∫•t: {context}

D·ª±a v√†o l·ªãch s·ª≠ c·ªßa kh√°ch tr√™n ƒë√¢y ƒë·ªÉ h·ªçc v·ªÅ kh√°ch h√†ng, r√∫t kinh nghi·ªám sai l·∫ßm c·ªßa m√¨nh v√† sau khi tr·∫£ l·ªùi, n·∫øu ph√π h·ª£p, h√£y h·ªèi kh√°ch m·ªôt c√¢u ti·∫øp theo.

`],
        ["human", `{raw}`]
    ]);
    const userQuestion = messages.at(-1)?.content || "";

    const encryptedMessage = encrypt(intent);
    const rawHistory = await aiChatbotModel.findByMessageAndEmail(encryptedMessage, email);

    // for (const row of rawHistory) {
    //     await addToVectorStore({
    //         question: row.question,
    //         answer: row.ai_answer,
    //         email,
    //         type: intent,
    //     }, "sql_docs");
    // }

    // console.log("‚úÖ Rebuilt Chroma memory from DB");

    const historyFormatted = rawHistory.map(row => {
        return `KH: ${row.question}\nAI: ${row.ai_answer}`;
    }).join("\n");

    const similar = await searchSimilar(userQuestion, 5, 0.5, "sql_docs");
    const context = similar.map(doc =>
        `KH: ${doc.pageContent}\nAI: ${doc.metadata.answer}`
    ).join("\n");

    console.log("‚úÖ context:", context);

    const refineChain = RunnableSequence.from([refinePrompt, model]);
    const refined = await refineChain.invoke({ raw, schema, historyFormatted, userQuestion, context });
    // const refined = await refineChain.invoke({ raw, schema, historyFormatted, userQuestion });


    console.log("‚úÖ AI response:", refined.content);

    return {
        refined: refined.content,
        resultMessage: raw,
        current_step: "responder"
    };
};

export const responder = async ({ refined, messages, email, sql, dbRows }) => {
    const safeAnswer = refined || "‚ùì Kh√¥ng c√≥ n·ªôi dung ph·∫£n h·ªìi.";
    await saveChatHistory({
        email,
        question: messages.at(-1)?.content || "",
        aiAnswer: safeAnswer,
        type: "sql",
        sql,
        dbRows
    });
    return {
        messages: [{ content: safeAnswer }],
        current_step: "__end__"
    };
};